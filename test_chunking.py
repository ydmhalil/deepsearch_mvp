#!/usr/bin/env python3
"""
Chunking Performance KarÅŸÄ±laÅŸtÄ±rma Testi
"""

import os
import sys
import json
from time import time

sys.path.append('.')

from chunker import chunk_text as old_chunk_text
from chunker_smart import SmartChunker
from utils import extract_text

def compare_chunking_performance():
    """Eski vs Yeni chunking sistemini karÅŸÄ±laÅŸtÄ±r"""
    
    print("ğŸ§ª CHUNKING PERFORMANCE KARÅILAÅTIRMASI")
    print("=" * 60)
    
    # Test dosyalarÄ±
    test_files = [
        './example_docs/rocket_instructions.txt',
        './example_docs/flight_manual.txt', 
        './test_docs/test_content.txt'
    ]
    
    chunker = SmartChunker()
    
    old_total_time = 0
    new_total_time = 0
    old_total_chunks = 0
    new_total_chunks = 0
    
    for file_path in test_files:
        if not os.path.exists(file_path):
            print(f"âš ï¸  Dosya bulunamadÄ±: {file_path}")
            continue
            
        print(f"\nğŸ“„ Test DosyasÄ±: {file_path}")
        text = extract_text(file_path)
        print(f"ğŸ“ Metin uzunluÄŸu: {len(text)} karakter, {len(text.split())} kelime")
        
        # ESKÄ° CHUNKING TESTÄ°
        start_time = time()
        old_chunks = old_chunk_text(text)
        old_time = time() - start_time
        old_total_time += old_time
        old_total_chunks += len(old_chunks)
        
        # YENÄ° CHUNKING TESTÄ°  
        start_time = time()
        new_chunks = chunker.chunk_document(text, file_path)
        new_time = time() - start_time
        new_total_time += new_time
        new_total_chunks += len(new_chunks)
        
        # KARÅILAÅTIRMA
        print(f"â±ï¸  Eski chunking: {old_time*1000:.2f}ms - {len(old_chunks)} chunks")
        print(f"âš¡ Yeni chunking: {new_time*1000:.2f}ms - {len(new_chunks)} chunks")
        
        if new_time > 0:
            speedup = old_time / new_time
            print(f"ğŸ“ˆ HÄ±z karÅŸÄ±laÅŸtÄ±rmasÄ±: {speedup:.2f}x {'HIZLI' if speedup > 1 else 'YAVAS'}")
        
        # METADATA KARÅILAÅTIRMASI
        if old_chunks and new_chunks:
            old_meta_fields = len(old_chunks[0]['meta'].keys())
            new_meta_fields = len(new_chunks[0]['meta'].keys())
            print(f"ğŸ·ï¸  Metadata zenginliÄŸi: {old_meta_fields} â†’ {new_meta_fields} fields (+{new_meta_fields-old_meta_fields})")
            
            print(f"ğŸ“‹ Yeni metadata alanlarÄ±:")
            new_fields = set(new_chunks[0]['meta'].keys()) - set(old_chunks[0]['meta'].keys())
            for field in sorted(new_fields):
                print(f"   + {field}: {new_chunks[0]['meta'][field]}")
    
    print("\n" + "=" * 60)
    print("ğŸ“Š GENEL PERFORMANS Ã–ZETÄ°")
    print(f"â±ï¸  Toplam eski chunking sÃ¼resi: {old_total_time*1000:.2f}ms")
    print(f"âš¡ Toplam yeni chunking sÃ¼resi: {new_total_time*1000:.2f}ms") 
    
    if new_total_time > 0:
        overall_speedup = old_total_time / new_total_time
        print(f"ğŸ“ˆ Genel hÄ±z iyileÅŸtirmesi: {overall_speedup:.2f}x")
    
    print(f"ğŸ”¢ Chunk sayÄ±larÄ±: {old_total_chunks} â†’ {new_total_chunks}")
    
    print("\nâœ… SMART CHUNKING Ã–ZELLÄ°KLERÄ°:")
    print("   â€¢ Belge tipine gÃ¶re adaptive strateji")
    print("   â€¢ Paragraf/cÃ¼mle sÄ±nÄ±rlarÄ±na saygÄ±lÄ±")
    print("   â€¢ Zengin metadata (dosya tipi, yapÄ±sal bilgi)")
    print("   â€¢ PowerPoint slide-bazlÄ± chunking")
    print("   â€¢ Excel sheet-bazlÄ± chunking")
    print("   â€¢ OCR iÃ§erik ayrÄ±mÄ±")

if __name__ == '__main__':
    compare_chunking_performance()